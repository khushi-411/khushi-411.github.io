---
layout: post
title: GSoC: Implementing log_ndtr!
date: 2022-06-26
category: gsoc
tags: 
- gsoc
- cupy
redirect_from:
- /gsoc/2022/06/26/GSoC: Implementing log_ndtr!/
- /GSoC: Implementing log_ndtr!.html
---

Heya! I'm excited to share my first week's experience
with my mentor, the CuPy, and the GSoC via this blog post.
Are you? It was a great week! Following the discussions
made in the community bonding period, I started working
on a special function, `log_ndtr`. I learned about the
CuPy ufuncs, numerical stability & optimizing the algorithm,
and off-course mathematical details about log_ndtr.
Let's get into the blog post to know more about it :)

Apart from log_ndtr, I worked on adding other
special functions, `expn` PR:
[#6790](https://github.com/cupy/cupy/pull/6790) and
`logsumexp` PR: [##6773](https://github.com/cupy/cupy/pull/6773)
that I believe are turning into an attractive shape.
I'll share more about them in my upcoming blog post.
This post is for log_ndtr!

I'm planning to structure the post as follows:
1. About `log_ndtr`
2. Universal Functions
3. Numerical Stability of Algorithm
4. Performance Benchmarks
5. Acknowledgement

Let's dig more ...

### **About `log_ndtr`**

log_ndtr calculates the area under the standard
Gaussian cumulative distribution function.

Mathematically, it is given by:

.. math::
    \text{log\_ndtr}(x) = \log\left(\frac{1}{\sqrt{2 \pi}}\int_{-\infty}^{x} e^{-\frac{1}{2}t^2} dt \right)

log_ndtr returns the area under the graph by
operating the element-by-element in the given
inputs. Such functions are known as universal
functionsâ€”more on this in the next section.

Since log_ndtr is a universal function, we
created a cupy.ufuncs to implement it and used
the following algorithm:
```cpp
static __device__ double log_ndtr(float x)
{
    float t = x * NPY_SQRT1_2;
    if (x < -1.0) {
        return log(erfcx(-t) / 2) - t * t;
    } else {
        return log1p(-erfc(t) / 2);
    }
}
```
Same for the single-precision version. I
initially used the templated version, but my
mentor guided me that single-precision versions
are faster on GPU, hence calculating for both
versions explicitly. And tada performance really
improved a lot. If you want to see that,
please [click this link](https://github.com/cupy/cupy/pull/6776#issuecomment-1154865687).

We implemented log_ndtr for floating-point
numbers and double data type versions. I
also added documentation and test for the same.
Yey completed the PR, and this got merged!
PR: [#6776](https://github.com/cupy/cupy/pull/6776).

Welcome `log_ndtr` to the CuPy! Here's how you can work on it:
```python
>>> import cupy
>>> import cupyx
>>> from cupyx.scipy.special import log_ndtr
>>> x = cupy.array([4, 4, 12, 13])
>>> cupyx.scipy.special.log_ndtr(x)
array([-3.16717434e-05, -3.16717434e-05, -1.77648211e-33, -6.11716440e-39])
>>>
```

### **Universal Functions**
Universal functions, a.k.a ufuncs, work on input
element-by-element patterns. CuPy's ufuncs are
written in Cython. And supports broadcasting,
type-promotion, and output type determinations
similar to NumPy. You can check the official
documentation for the same
[link here](https://docs.cupy.dev/en/stable/reference/ufunc.html).
Ufuncs are called by using `create_ufunc` defined
at [cupy/_core/_kernel.pyx](https://github.com/cupy/cupy/blob/master/cupy/_core/_kernel.pyx).
```cython
cpdef create_ufunc(name, ops, routine=None, preamble='', doc='',
                   default_casting=None, loop_prep='', out_ops=None,
                   cutensor_op=None):
    ops_ = _Ops.from_tuples(ops, routine)
    _out_ops = None if out_ops is None else _Ops.from_tuples(out_ops, routine)
    return ufunc(
        name, ops_.nin, ops_.nout, ops_, preamble,
        loop_prep, doc, default_casting=default_casting, out_ops=_out_ops,
        cutensor_op=cutensor_op)
```
This functions calls the ufunc class
defined [here](https://github.com/cupy/cupy/blob/master/cupy/_core/_kernel.pyx#L1071-L1326).

We created a ufunc for log_ndtr as follows:
```python
log_ndtr = _core.create_ufunc(
    'cupyx_scipy_special_log_ndtr',
    (('f->f', 'out0 = log_ndtrf(in0)'), 'd->d'),
    'out0 = log_ndtr(in0)',
    preamble=log_ndtr_definition,
    doc="""
    ....
    """
)
```
Here,
- `cupyx_scipy_special_log_ndtr`: name of the function
- `(('f->f', 'out0 = log_ndtrf(in0)'), 'd->d')`: Input dtypes.
It shows the float32 input will return float32
input and we will use the single precision
version for the calculation. Second thing
is it says float64 inputs will output
float64 type and use the default type for its calculation.
- `out0 = log_ndtr(in0)`: It's the default output type.
- `preamble=log_ndtr_definition`: we wrote the
definition of function explicitly in the function.
- `doc`: the documentation part.

### **Numerical Stability of Algorithm**
This is probably a mind-refreshing part of this post.
You might be thinking, as the name suggests, log_ndtr,
we could have simply implemented as `log(ndtr)`.
Have you thought? I thought so. But as caught in the
SciPy issue, for x in [-20, 6], the relative error
multiplies when x is positive.

We in CuPy restructured the algorithm to use
`erfc` and `erfcx` functions to avoid loss
of precision. ScIPy's work inspires this!

### **Performance Benchmarks**
The most crucial part! We focussed on the performance
for our impl a lot. In a short summary, we implemented
cupy.ufuncs for performance reasons. Secondly,
and more imported, we implemented single and
double precision versions separately to get an
advantage of GPU. We achieved approximately 30%
faster speed for float32 than float64. Also, CuPy's
performance compared to SciPy's performance is remarkable! 

Here's the benchmark ...
size | dtype | SciPy | CuPy
-----|-------|-------|-----
1000 | int8 | 0.026 ms | 0.018 ms
1000 | int32 | 0.026 ms | 0.020 ms
1000 | uint32 | 0.025 ms | 0.020 ms
1000 | float32 | 0.025 ms | 0.017 ms
1000 | float64 | 0.024 ms | 0.020 ms
100000 | int8 | 2.159 ms | 0.061 ms
100000 | int32 | 2.038 ms | 0.339 ms
100000 | uint32 | 2.059 ms | 0.338 ms
100000 | float32 | 2.169 ms | 0.024 ms
100000 | float64 | 2.005 ms | 0.339 ms
1000000 | int8 | 21.383 ms | 0.118 ms
1000000 | int32 | 20.215 ms | 3.258 ms
1000000 | uint32 | 20.402 ms | 3.258 ms
1000000 | float32 | 21.290 ms | 0.119 ms
1000000 | float64 | 19.824 ms | 3.261 ms

Please note my system configurations are NVIDIA
GEFORCE GTX board, Intel(R) Core(TM) i7-10870H CPU Model,
and DDR4, 16GB RAM model. You may get slightly different
comparisons in your system.

### **Acknowledgement**
I thank my mentor [Masayuki Takagi](https://github.com/takagi)
for his guidance, for reviewing my work,
and giving valuable suggestions to improve our
implementation. It's great connecting with you. Thank you!

I also want to acknowledge the SciPy team for
their implementation; their work inspires this. Thank you, SciPy!
